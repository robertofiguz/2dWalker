{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b97f1a1eec294e3eaf723778bd3c4beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76e4f192ead94799a2300ba0c67169bb",
              "IPY_MODEL_39996fdce5fe40ffa0fca22c43b6b51c",
              "IPY_MODEL_8e993006ac0948eab07e9b9004f4eb63"
            ],
            "layout": "IPY_MODEL_c387078edd284fb5a2e6bb989e732aed"
          }
        },
        "76e4f192ead94799a2300ba0c67169bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc16ff1e70a645f19e356f3fd73792cc",
            "placeholder": "​",
            "style": "IPY_MODEL_a3503db8a43b42c89ac07b71cca0144e",
            "value": "model.safetensors: 100%"
          }
        },
        "39996fdce5fe40ffa0fca22c43b6b51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3ecae9beb8f4dbbba4b987afb418dab",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b75dff13a1734179af9d016172d3808f",
            "value": 440449768
          }
        },
        "8e993006ac0948eab07e9b9004f4eb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a595746f69471dade5e495d1a3b1aa",
            "placeholder": "​",
            "style": "IPY_MODEL_69e8884da89a400c98ecd6bd577a324e",
            "value": " 440M/440M [00:02&lt;00:00, 229MB/s]"
          }
        },
        "c387078edd284fb5a2e6bb989e732aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc16ff1e70a645f19e356f3fd73792cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3503db8a43b42c89ac07b71cca0144e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ecae9beb8f4dbbba4b987afb418dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b75dff13a1734179af9d016172d3808f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13a595746f69471dade5e495d1a3b1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e8884da89a400c98ecd6bd577a324e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertofiguz/2dWalker/blob/main/RI_practical_tutorial_5_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ym64qNwntmj",
        "outputId": "cd9f58df-9c84-4fa6-df05-def4e386dd19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting ranx\n",
            "  Downloading ranx-0.3.19-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.10/dist-packages (from ranx) (0.58.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ranx) (1.5.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ranx) (0.9.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ranx) (1.11.4)\n",
            "Collecting ir-datasets (from ranx)\n",
            "  Downloading ir_datasets-0.5.5-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.0/318.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ranx) (13.7.0)\n",
            "Collecting orjson (from ranx)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4 (from ranx)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cbor2 (from ranx)\n",
            "  Downloading cbor2-5.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.3/228.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from ranx) (0.12.2)\n",
            "Collecting fastparquet (from ranx)\n",
            "  Downloading fastparquet-2023.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54.1->ranx) (0.41.1)\n",
            "Collecting cramjam>=2.3 (from fastparquet->ranx)\n",
            "  Downloading cramjam-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ranx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ranx) (2023.3.post1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx) (4.11.2)\n",
            "Collecting inscriptis>=2.2.0 (from ir-datasets->ranx)\n",
            "  Downloading inscriptis-2.3.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx) (4.9.3)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir-datasets->ranx)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Collecting warc3-wet>=0.2.3 (from ir-datasets->ranx)\n",
            "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir-datasets->ranx)\n",
            "  Downloading zlib-state-0.1.6.tar.gz (9.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ijson>=3.1.3 (from ir-datasets->ranx)\n",
            "  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyautocorpus>=0.1.1 (from ir-datasets->ranx)\n",
            "  Downloading pyautocorpus-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unlzw3>=0.2.1 (from ir-datasets->ranx)\n",
            "  Downloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx) (2.16.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->ranx) (3.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx) (2.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ranx) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ranx) (1.16.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: warc3-wet-clueweb09, zlib-state, cbor\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=df650f0334eac1b18efe57a10366335a3baaee2ce127a4a9974564335fbff141\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
            "  Building wheel for zlib-state (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zlib-state: filename=zlib_state-0.1.6-cp310-cp310-linux_x86_64.whl size=21161 sha256=d59ccbe25b4be90cbe80f6bdda70c2110cf50769723b79f63514c196d6a70c9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/72/7e/aff80f26e926b6e1fb08dfb52aba03c0e058f5e2258deb50a9\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53431 sha256=e209b1bab54fff2b558fd671c59fb82ca9d71273030332d94261d79bb6bad93b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
            "Successfully built warc3-wet-clueweb09 zlib-state cbor\n",
            "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, trec-car-tools, pyautocorpus, orjson, lz4, cramjam, cbor2, inscriptis, ir-datasets, fastparquet, accelerate, ranx\n",
            "Successfully installed accelerate-0.25.0 cbor-1.0.0 cbor2-5.5.1 cramjam-2.7.0 fastparquet-2023.10.1 ijson-3.2.3 inscriptis-2.3.2 ir-datasets-0.5.5 lz4-4.3.2 orjson-3.9.10 pyautocorpus-0.1.12 ranx-0.3.19 trec-car-tools-2.6 unlzw3-0.2.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.6\n",
            "Cloning into 'Neural-IR-hands-on'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 116 (delta 65), reused 40 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (116/116), 3.35 MiB | 14.91 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers ranx accelerate\n",
        "!git clone https://github.com/ua-deti-information-retrieval/Neural-IR-hands-on.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://uapt33090-my.sharepoint.com/:u:/g/personal/robertof_ua_pt/EfppcbhRSFxPpAAncnTmslsBUsTvmRuLVoAo9nH2seAQUQ?e=qGN8dy\\&download=1 -O evaluation-tiny.jsonl\n",
        "\n",
        "!wget https://uapt33090-my.sharepoint.com/:u:/g/personal/robertof_ua_pt/EegdNa9Osq9GmDZCjgRNjw0BKFDoqfVE6-mDex9y4_Ly3g?e=subhDA\\&download=1 -O evaluation-small.jsonl\n",
        "\n",
        "!wget https://uapt33090-my.sharepoint.com/:u:/g/personal/robertof_ua_pt/ETKpLzk_gjtGjQJGxyI36SAB4ni43-T5yB8nNV34myDjHQ\\?e\\=Vf7UGh\\&download=1 -O text_collections.jsonl\n",
        "\n",
        "!wget https://uapt33090-my.sharepoint.com/:u:/g/personal/robertof_ua_pt/EckqcQeakvZFuiQ55OYg7esBBmGUFv_ny_uZkNaablfA-w?e=DZ1lEf\\&download=1 -O train_set_pos.jsonl\n",
        "\n",
        "!wget https://uapt33090-my.sharepoint.com/:u:/g/personal/robertof_ua_pt/EYbLiQmpgpFCgrErcJKGNQoBU0RDlOZcHCF9FW-xTB3F3g?e=dbFFYZ\\&download=1 -O train_set_neg.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhTjVDS5EiM9",
        "outputId": "e352f286-ee64-4c20-d615-ef61e5fab9f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-16 00:03:03--  https://uapt33090-my.sharepoint.com/:u:/g/personal/robertof_ua_pt/EfppcbhRSFxPpAAncnTmslsBUsTvmRuLVoAo9nH2seAQUQ?e=qGN8dy&download=1\n",
            "Resolving uapt33090-my.sharepoint.com (uapt33090-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to uapt33090-my.sharepoint.com (uapt33090-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/robertof_ua_pt/Documents/new_sets/question_E9B1.jsonl?ga=1 [following]\n",
            "--2023-12-16 00:03:04--  https://uapt33090-my.sharepoint.com/personal/robertof_ua_pt/Documents/new_sets/question_E9B1.jsonl?ga=1\n",
            "Reusing existing connection to uapt33090-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11183 (11K) [application/octet-stream]\n",
            "Saving to: ‘evaluation-tiny.jsonl’\n",
            "\n",
            "evaluation-tiny.jso 100%[===================>]  10.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-16 00:03:04 (122 MB/s) - ‘evaluation-tiny.jsonl’ saved [11183/11183]\n",
            "\n",
            "--2023-12-16 00:03:04--  https://uapt33090-my.sharepoint.com/:u:/g/personal/robertof_ua_pt/EegdNa9Osq9GmDZCjgRNjw0BKFDoqfVE6-mDex9y4_Ly3g?e=subhDA&download=1\n",
            "Resolving uapt33090-my.sharepoint.com (uapt33090-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to uapt33090-my.sharepoint.com (uapt33090-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/robertof_ua_pt/Documents/new_sets/question_E9B2.jsonl?ga=1 [following]\n",
            "--2023-12-16 00:03:05--  https://uapt33090-my.sharepoint.com/personal/robertof_ua_pt/Documents/new_sets/question_E9B2.jsonl?ga=1\n",
            "Reusing existing connection to uapt33090-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10951 (11K) [application/octet-stream]\n",
            "Saving to: ‘evaluation-small.jsonl’\n",
            "\n",
            "evaluation-small.js 100%[===================>]  10.69K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-16 00:03:05 (164 MB/s) - ‘evaluation-small.jsonl’ saved [10951/10951]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting here"
      ],
      "metadata": {
        "id": "Pdxc8QkT87U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Neural-IR-hands-on && git pull\n",
        "\n",
        "!cp Neural-IR-hands-on/trainer/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u822MM7j88ej",
        "outputId": "403cdce5-2a67-4c4d-f19a-64dc1b470722"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data import get_qrels, InferenceRankingIterator,  BioASQPointwiseIterator, InferenceDataset, create_training_dataset\n",
        "from sampler import BasicSampler\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenizer.model_max_length = 512\n",
        "\n",
        "# torch.utils.data.Dataset (Iterable)\n",
        "train_ds = create_training_dataset(\"train_set_pos.jsonl\", # \"body\"/\"question\" q_id:[doc_id] 60K\n",
        "                                   \"train_set_neg.jsonl\", # q_id:[{\"id\":doc_id, \"score\": doc_id}]\n",
        "                                   \"text_collections.jsonl\", # doc_id: text (title + \" \" + abstract)\n",
        "                                    tokenizer=tokenizer,\n",
        "                                    iterator_class=BioASQPointwiseIterator[BasicSampler],\n",
        "                                    #max_questions=500, # debug\n",
        "                                            )\n",
        "# torch.utils.data.Dataset (Iterable)\n",
        "dev_ds = InferenceDataset(\"evaluation-small.jsonl\", #q_id:[doc_id ->>] BM25 top-1000 top-100 # 100 question -> 1000 docs\n",
        "                          train_ds.collection,\n",
        "                          tokenizer,\n",
        "                          #max_questions=10, # debug\n",
        "                          at=100, #max docs\n",
        "                          gs_path=\"dev_set_nq_gs.jsonl\", # q_id: [doc_id]\n",
        "                          iterator_class=InferenceRankingIterator)\n"
      ],
      "metadata": {
        "id": "aPyHGgf09BKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "a4a91762-85d9-4a86-de84-d6ee89a6e868"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b0f2c745d3c9>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                                             )\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# torch.utils.data.Dataset (Iterable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m dev_ds = InferenceDataset(\"evaluation-small.jsonl\", #q_id:[doc_id ->>] BM25 top-1000 top-100 # 100 question -> 1000 docs\n\u001b[0m\u001b[1;32m     20\u001b[0m                           \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                           \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bm25_run_path, collection, tokenizer, iterator_class, gs_path, max_length, at, max_questions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm25_run_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             dataset = {q_data[\"id\"]:{\"documents\":q_data[\"documents\"][:at],\n\u001b[0m\u001b[1;32m    158\u001b[0m                                           \"question\":q_data[\"question\"]} for q_data in map(json.loads, f)} \n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/data.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm25_run_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             dataset = {q_data[\"id\"]:{\"documents\":q_data[\"documents\"][:at],\n\u001b[0m\u001b[1;32m    158\u001b[0m                                           \"question\":q_data[\"question\"]} for q_data in map(json.loads, f)} \n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "id2label = {0: \"IRRELEVANT\", 1: \"RELEVANT\"}\n",
        "label2id = {\"IRRELEVANT\": 0, \"RELEVANT\": 1}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b97f1a1eec294e3eaf723778bd3c4beb",
            "76e4f192ead94799a2300ba0c67169bb",
            "39996fdce5fe40ffa0fca22c43b6b51c",
            "8e993006ac0948eab07e9b9004f4eb63",
            "c387078edd284fb5a2e6bb989e732aed",
            "bc16ff1e70a645f19e356f3fd73792cc",
            "a3503db8a43b42c89ac07b71cca0144e",
            "a3ecae9beb8f4dbbba4b987afb418dab",
            "b75dff13a1734179af9d016172d3808f",
            "13a595746f69471dade5e495d1a3b1aa",
            "69e8884da89a400c98ecd6bd577a324e"
          ]
        },
        "id": "4fx2wIkv9xnS",
        "outputId": "00a25ff1-ef3d-4225-e773-63798e2943c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b97f1a1eec294e3eaf723778bd3c4beb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_iter = iter(train_ds)\n",
        "\n",
        "print(next(_iter))\n",
        "print(next(_iter))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr5uKmljK7f-",
        "outputId": "71802e85-e06e-471a-84cd-98cc4560b9b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 2054, 2024, 1040, 7849, 5104, 1029, 102, 1031, 5923, 1998, 11122, 11733, 3351, 6215, 1999, 10958, 1998, 2049, 8830, 1012, 4295, 1011, 29226, 3424, 25032, 14820, 12070, 5850, 1033, 1012, 1996, 3078, 3125, 1999, 1996, 3949, 1997, 1054, 5369, 12248, 3406, 3593, 27641, 1006, 10958, 1007, 2003, 2000, 5441, 2204, 3737, 1997, 2166, 2011, 10723, 4101, 6215, 1998, 9992, 11980, 1012, 2005, 2023, 3800, 1010, 2035, 5022, 2007, 1996, 11616, 1997, 10958, 2323, 2022, 5845, 2011, 4295, 1011, 29226, 3424, 25032, 14820, 12070, 5850, 1006, 1040, 7849, 5104, 1007, 2164, 16012, 27179, 1040, 7849, 5104, 1998, 2512, 1011, 16012, 27179, 1040, 7849, 5104, 1012, 2035, 1040, 7849, 5104, 2024, 3517, 2000, 4652, 1996, 14967, 1997, 5923, 1998, 11122, 11733, 3351, 6215, 1997, 10958, 5022, 2013, 1996, 3463, 1997, 1999, 25714, 2470, 1010, 1998, 9740, 1997, 4101, 6215, 2003, 4484, 1999, 24269, 1999, 2035, 16012, 27179, 1040, 7849, 5104, 1010, 2021, 2025, 1999, 2035, 2512, 1011, 16012, 27179, 1040, 7849, 5104, 1012, 1999, 2023, 3127, 1010, 2057, 2052, 2066, 2000, 3319, 1996, 3463, 1997, 3937, 27338, 1998, 6612, 2913, 2000, 10580, 1996, 9740, 1997, 4101, 6215, 2011, 2512, 1011, 16012, 27179, 1040, 7849, 5104, 2008, 2031, 2042, 4703, 2109, 1045, 3679, 3218, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label_ids': 1}\n",
            "{'input_ids': [101, 2054, 2003, 2273, 9247, 2937, 6721, 3989, 1029, 102, 2054, 2003, 1996, 3465, 1997, 12646, 1029, 1996, 2523, 2001, 2146, 5204, 2008, 12646, 2007, 8985, 2491, 8853, 1998, 7040, 2001, 2383, 1037, 3278, 3466, 2006, 11394, 6078, 1012, 2005, 2008, 3114, 1010, 9556, 2013, 1996, 2783, 5002, 2020, 2025, 11341, 1012, 2045, 2001, 1010, 2174, 1010, 2019, 4297, 28040, 9153, 3468, 2342, 2000, 8145, 10480, 2951, 2006, 1996, 4254, 8985, 2491, 5918, 2020, 2383, 2006, 11394, 6078, 1012, 2023, 2001, 3391, 10232, 2445, 1996, 4417, 5966, 2090, 9808, 3270, 1005, 1055, 2219, 12646, 3465, 10035, 1998, 1996, 6322, 1997, 11394, 5427, 11363, 1998, 11394, 6078, 1012, 2023, 3720, 3640, 1037, 4766, 19184, 1997, 1037, 2200, 16030, 1998, 7721, 5002, 1012, 1037, 2062, 3143, 6412, 1997, 1996, 9556, 2097, 2022, 3591, 2000, 1996, 2807, 15262, 2160, 1997, 10284, 2083, 2473, 4311, 1012, 3463, 2036, 2097, 2022, 4487, 11393, 26972, 2000, 15262, 6736, 2005, 2224, 1999, 6413, 2523, 3454, 1998, 3450, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label_ids': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(num_train_epochs=5,\n",
        "                                  learning_rate=2e-5, # AdamW\n",
        "                                  weight_decay=0.01,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=32,\n",
        "                                  evaluation_strategy= \"epoch\",\n",
        "                                  dataloader_pin_memory=True,\n",
        "                                  output_dir=\"trained_model\",\n",
        "                                  logging_strategy=\"steps\",\n",
        "                                  logging_first_step=True,\n",
        "                                  logging_steps=100,\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  save_total_limit=2,\n",
        "                                  seed=42)"
      ],
      "metadata": {
        "id": "a1MsAs1ZCrH0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ranker_trainer import RankerTrainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from collator import RankingCollator\n",
        "from metrics import RanxMetrics\n",
        "\n",
        "import torch\n",
        "trainer = RankerTrainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_ds,\n",
        "      eval_dataset=dev_ds, # validation set\n",
        "      tokenizer=tokenizer,\n",
        "      data_collator=DataCollatorWithPadding(tokenizer=tokenizer), # apply to train\n",
        "      eval_data_collator=RankingCollator(tokenizer=tokenizer), # apply to val\n",
        "      preprocess_logits_for_metrics=lambda logits, labels: torch.nn.functional.softmax(logits, dim=-1)[:,1], # prob for class 1 (relevant class)\n",
        "      compute_metrics=RanxMetrics(dev_ds.get_qrels()),\n",
        "  )"
      ],
      "metadata": {
        "id": "65IrTov_Dkx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "0d034df2-76d4-4e5e-9896-ac43087acafb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b54374ccf888>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# apply to train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dev_ds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "IxbTcUF5Lx82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use a trained model to run inference!\n",
        "\n",
        "## TODO reboot the machine"
      ],
      "metadata": {
        "id": "Ug88u-hCkxIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_checkpoint = \"trained_model/checkpoint-250\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenizer.model_max_length = 512\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint).to(\"cuda\")"
      ],
      "metadata": {
        "id": "dZ3J_cxdL6C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import load_collection_lookup\n",
        "from data import InferenceRankingIterator, InferenceDataset\n",
        "from collator import RankingCollator\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "# i am using the dev dataset bc I do not have eval dataset for this example\n",
        "\n",
        "# load the collection lookup\n",
        "collection = load_collection_lookup(\"collection_with_texts.jsonl\")\n",
        "\n",
        "eval_ds = InferenceDataset(\"dev_set_nq_bm25.jsonl\",\n",
        "                            collection,\n",
        "                            tokenizer,\n",
        "                            at=100, #max docs pq q\n",
        "                            iterator_class=InferenceRankingIterator)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(eval_ds,\n",
        "                                         batch_size=32,\n",
        "                                         pin_memory=True,\n",
        "                                         collate_fn=RankingCollator(tokenizer))"
      ],
      "metadata": {
        "id": "X4csUXb-Svoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_sample = next(iter(dataloader))\n",
        "\n",
        "_sample[\"inputs\"].input_ids.shape"
      ],
      "metadata": {
        "id": "FhE-CjadJ2ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "run_dict = defaultdict(list) # q_id:[{\"doc_id\": doc_id, \"score\": prob}]\n",
        "\n",
        "for sample in tqdm(dataloader):\n",
        "  _inputs = sample[\"inputs\"].to(\"cuda\") # send inputs to gpu\n",
        "\n",
        "  # run inference\n",
        "  with torch.no_grad():\n",
        "    logits = model(**_inputs).logits # 0->value, 1->value\n",
        "\n",
        "    # based on the logits, we normalize to have a probabilistic distribution\n",
        "    # and we extract the probability of that query-doc pair being relevant!\n",
        "    prob_relevant_pair = torch.nn.functional.softmax(logits, dim=-1)[:,1] # [0-1]\n",
        "    # 32,\n",
        "\n",
        "  for i, q_id in enumerate(sample[\"id\"]):\n",
        "    run_dict[q_id].append({\"doc_id\":sample[\"doc_id\"][i],\n",
        "                           \"score\":prob_relevant_pair[i].item()})\n"
      ],
      "metadata": {
        "id": "dA7HjR_ITQY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lest sort by the neural IR model prob and we have our reranked order!\n",
        "for q_id in run_dict:\n",
        "  run_dict[q_id].sort(key=lambda x:-x[\"score\"]) #prob\n"
      ],
      "metadata": {
        "id": "_06xHlg0P9Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_dict[\"test100\"]"
      ],
      "metadata": {
        "id": "vkFrQKtsQv0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAoqOF76RXvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8Il4oKEaFhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJgBwbKvaFKn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}